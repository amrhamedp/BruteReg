{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%reset\n",
    "import sys\n",
    "sys.path.append('/usr/local/lib/python2.7/site-packages')\n",
    "sys.path.append('./modules')\n",
    "\n",
    "import warnings\n",
    "#import re\n",
    "\n",
    "import pandas as pd\n",
    "#import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "## import modules to build pipelines\n",
    "import pipemodules as pm\n",
    "import projecthandle as proj\n",
    "import run_grid as rg\n",
    "\n",
    "#% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Read csv file containing descriptors\n",
    "descriptors_raw = pd.read_csv('./rdkit_descriptors.csv')\n",
    "labels = descriptors_raw.iloc[:,0]\n",
    "X = descriptors_raw.iloc[:,2:]\n",
    "y = descriptors_raw.iloc[:,1]\n",
    "\n",
    "del descriptors_raw\n",
    "\n",
    "#range(10,100,10),\n",
    "#,2,3,4,6,7,8,9,10,11,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.094e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=5.470e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=3.718e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 35 iterations, alpha=1.660e-03, previous alpha=1.599e-03, with an active set of 28 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.086e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.429e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.522e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 25 iterations, alpha=1.441e-03, previous alpha=1.111e-03, with an active set of 22 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=5.470e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.718e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 38 iterations, alpha=2.026e-03, previous alpha=1.933e-03, with an active set of 29 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.091e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.456e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.455e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=9.641e-04, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 36 iterations, alpha=6.948e-04, previous alpha=6.913e-04, with an active set of 29 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/linalg/basic.py:884: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.116e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=5.580e-03, with an active set of 15 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=5.139e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.825e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=3.009e-03, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.712e-03, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=1.712e-03, with an active set of 31 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=1.527e-03, with an active set of 32 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=1.294e-03, with an active set of 35 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 49 iterations, alpha=1.350e-03, previous alpha=1.203e-03, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.089e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=5.444e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=6.163e-04, with an active set of 28 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 68 iterations, alpha=3.446e-04, previous alpha=3.432e-04, with an active set of 37 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 95 iterations, alpha=3.059e-03, previous alpha=2.318e-04, with an active set of 60 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=2.674e-03, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=2.654e-03, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.189e-03, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.731e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 56 iterations, alpha=1.324e-03, previous alpha=1.323e-03, with an active set of 43 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=7.644e-04, with an active set of 49 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=7.487e-04, with an active set of 51 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 68 iterations, alpha=6.814e-04, previous alpha=6.677e-04, with an active set of 53 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.445e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.636e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=3.068e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=8.676e-04, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=4.330e-04, with an active set of 38 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 55 iterations, alpha=3.836e-04, previous alpha=3.584e-04, with an active set of 40 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=7.092e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=3.546e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=8.593e-04, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 56 iterations, alpha=4.784e-04, previous alpha=4.752e-04, with an active set of 33 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.841e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=5.410e-03, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=3.459e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=3.452e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 37 iterations, alpha=1.829e-03, previous alpha=1.636e-03, with an active set of 26 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 84 iterations, alpha=1.220e-03, previous alpha=1.459e-04, with an active set of 55 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 85 iterations, alpha=3.693e-03, previous alpha=7.821e-05, with an active set of 58 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 89 iterations, alpha=4.510e-03, previous alpha=8.756e-05, with an active set of 60 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:43: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/coordinate_descent.py:470: UserWarning: Coordinate descent with alpha=0 may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.415e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=4.493e-03, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 40 iterations, alpha=2.003e-03, previous alpha=1.985e-03, with an active set of 31 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.949e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=2.465e-03, with an active set of 29 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 34 iterations, alpha=2.458e-03, previous alpha=2.317e-03, with an active set of 29 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.712e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 89 iterations, alpha=9.045e-03, previous alpha=3.818e-03, with an active set of 54 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.415e-02, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=4.493e-03, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 33 iterations, alpha=2.000e-03, previous alpha=1.928e-03, with an active set of 28 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=2.465e-03, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=2.325e-03, previous alpha=2.188e-03, with an active set of 27 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.712e-02, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 86 iterations, alpha=6.037e-03, previous alpha=2.879e-03, with an active set of 51 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 75 iterations, alpha=1.179e-02, previous alpha=8.339e-05, with an active set of 52 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 83 iterations, alpha=3.121e-03, previous alpha=6.087e-05, with an active set of 56 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=5.762e-05, with an active set of 58 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 79 iterations, alpha=3.130e-02, previous alpha=5.266e-05, with an active set of 58 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=7.343e-05, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 77 iterations, alpha=3.843e-03, previous alpha=5.981e-05, with an active set of 52 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.042e-03, with an active set of 34 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=4.281e-04, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 75 iterations, alpha=3.831e-04, previous alpha=3.564e-04, with an active set of 56 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 86 iterations, alpha=7.743e-03, previous alpha=1.106e-04, with an active set of 55 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=2.505e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.461e-03, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 34 iterations, alpha=9.918e-04, previous alpha=9.693e-04, with an active set of 29 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=1.311e-03, with an active set of 40 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=1.150e-03, with an active set of 43 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 62 iterations, alpha=1.070e-03, previous alpha=1.021e-03, with an active set of 43 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=7.305e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.116e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=6.066e-03, previous alpha=6.008e-03, with an active set of 14 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 98 iterations, alpha=9.261e-04, previous alpha=1.206e-04, with an active set of 61 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 76 iterations, alpha=2.338e-03, previous alpha=1.425e-04, with an active set of 49 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=3.475e-04, with an active set of 47 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=3.421e-04, with an active set of 48 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=1.816e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=1.698e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 81 iterations, alpha=1.707e-04, previous alpha=1.566e-04, with an active set of 56 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 71 iterations, alpha=5.404e+00, previous alpha=1.082e-02, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 79 iterations, alpha=3.443e+00, previous alpha=4.276e-03, with an active set of 44 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=2.631e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=2.411e-03, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.825e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=2.411e-03, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=2.031e-03, previous alpha=2.003e-03, with an active set of 27 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 78 iterations, alpha=7.333e+01, previous alpha=2.137e-02, with an active set of 41 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 69 iterations, alpha=1.577e+00, previous alpha=1.990e-02, with an active set of 32 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 72 iterations, alpha=2.591e+00, previous alpha=5.016e-03, with an active set of 39 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=6.166e-02, with an active set of 25 regressors, and the smallest cholesky pivot element being 8.429e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=2.449e-02, with an active set of 30 regressors, and the smallest cholesky pivot element being 8.429e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=2.380e-02, with an active set of 30 regressors, and the smallest cholesky pivot element being 8.429e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 63 iterations, alpha=2.223e-02, previous alpha=2.200e-02, with an active set of 32 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 53 iterations, alpha=4.657e-02, previous alpha=4.296e-02, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 66 iterations, alpha=3.226e-02, previous alpha=1.807e-02, with an active set of 43 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 71 iterations, alpha=1.493e-02, previous alpha=1.318e-02, with an active set of 44 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=5.596e-02, with an active set of 30 regressors, and the smallest cholesky pivot element being 8.429e-08\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 74 iterations, alpha=1.974e-02, previous alpha=1.757e-02, with an active set of 43 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=1.826e-01, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 50 iterations, alpha=9.492e-02, previous alpha=8.713e-02, with an active set of 29 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=1.374e-02, with an active set of 44 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=6.401e-03, with an active set of 50 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 89 iterations, alpha=3.253e+01, previous alpha=6.401e-03, with an active set of 50 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=1.219e-02, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 93 iterations, alpha=3.506e-01, previous alpha=8.354e-03, with an active set of 52 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=5.505e-02, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 78 iterations, alpha=2.431e-02, previous alpha=2.160e-02, with an active set of 43 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 75 iterations, alpha=2.341e+01, previous alpha=1.340e-02, with an active set of 38 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 65 iterations, alpha=7.198e+00, previous alpha=7.814e-03, with an active set of 36 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 25 iterations, alpha=6.344e-01, previous alpha=6.344e-01, with an active set of 16 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 64 iterations, alpha=3.517e+00, previous alpha=1.049e-02, with an active set of 31 regressors.\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.384e+00, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.192e+00, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/Users/res3/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 44 iterations, alpha=1.261e-01, previous alpha=1.113e-01, with an active set of 25 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pipemodules as pm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "results.reset_index(drop=True, inplace=True)\n",
    "\n",
    "## filter results and eliminate poor models\n",
    "for i in range(0,len(results)):\n",
    "    if results.mean_train_score[i] > 0.75 and abs(results.mean_test_score[i] - results.mean_train_score[i]) < 0.15:\n",
    "        continue\n",
    "    else: \n",
    "        results.drop(i, axis=0, inplace=True)\n",
    "\n",
    "results.reset_index(drop=True, inplace=True)\n",
    "\n",
    "## create analysis set\n",
    "# set arrays for results\n",
    "dev_set_score = []\n",
    "eval_set_score = []\n",
    "dev_evs = []\n",
    "eval_evs = []\n",
    "dev_mae = []\n",
    "eval_mae = []\n",
    "dev_mse = []\n",
    "eval_mse = []\n",
    "dev_medae = []\n",
    "eval_medae = []\n",
    "method_ids = []\n",
    "parameters = []\n",
    "\n",
    "\n",
    "for i in range(0,len(results)):\n",
    "    ## take method_ids and build estimator for current method\n",
    "    string = results.method_ids[i] # retrive method id\n",
    "    setup = eval(string) # convert to iterable array\n",
    "\n",
    "    temp = pm.search_random_forest() #initiate class\n",
    "\n",
    "    # set the estimator type and initiate estimator class\n",
    "    _,clf,_ = temp.set_method(setup[2]) \n",
    "    \n",
    "    # get the development set features\n",
    "    X_dev_temp, _ = pm.get_X(dev_set.matrix_raw, \\\n",
    "                             meth.indvals[setup[0]][setup[1]]) \n",
    "    # get the evaluation set features\n",
    "    X_eval_temp, _ = pm.get_X(eval_set.matrix_raw, \\\n",
    "                              meth.indvals[setup[0]][setup[1]]) \n",
    "\n",
    "    del temp\n",
    "\n",
    "    # retreive hyper-parameters\n",
    "    params = results['params'][i]\n",
    "    # set estimator hyper-parameters\n",
    "    clf.set_params(**params)\n",
    "    \n",
    "    # fit the estimator to the development set\n",
    "    clf.fit(X_dev_temp, dev_set.y_raw)\n",
    "    # predict the evaluation set\n",
    "    eval_predict = clf.predict(X_eval_temp)\n",
    "    # predict the development set - for metrics\n",
    "    dev_predict = clf.predict(X_dev_temp)\n",
    "    \n",
    "    # add calculated metrics, methods, and parameters to lists for results\n",
    "    dev_set_score.append(clf.score(X_dev_temp, dev_set.y_raw))\n",
    "    eval_set_score.append(clf.score(X_eval_temp, eval_set.y_raw))\n",
    "    dev_evs.append(metrics.explained_variance_score(dev_predict, dev_set.y_raw))\n",
    "    eval_evs.append(metrics.explained_variance_score(eval_predict, eval_set.y_raw))\n",
    "    dev_mae.append(metrics.mean_absolute_error(dev_predict, dev_set.y_raw))\n",
    "    eval_mae.append(metrics.mean_absolute_error(eval_predict, eval_set.y_raw))\n",
    "    dev_mse.append(metrics.mean_squared_error(dev_predict, dev_set.y_raw))\n",
    "    eval_mse.append(metrics.mean_squared_error(eval_predict, eval_set.y_raw))\n",
    "    dev_medae.append(metrics.median_absolute_error(dev_predict, dev_set.y_raw))\n",
    "    eval_medae.append(metrics.median_absolute_error(eval_predict, eval_set.y_raw))\n",
    "    method_ids.append(string)\n",
    "    parameters.append(params)\n",
    "    \n",
    "# create dictionary object from results\n",
    "evaluation_results = {'dev_set_score':dev_set_score, 'eval_set_score':eval_set_score, \\\n",
    "                     'method_ids':method_ids, 'parameters':parameters, 'dev_evs':dev_evs, \\\n",
    "                     'eval_evs':eval_evs, 'dev_mae':dev_mae, 'eval_mae':eval_mae, \\\n",
    "                     'dev_mse': dev_mse, 'eval_mse':eval_mse, 'dev_median_ae':dev_medae, \\\n",
    "                     'eval_median_ae':eval_medae}\n",
    "\n",
    "# re-rank and sort filtered methods by test-score (r**2)\n",
    "analysis_set = pd.DataFrame(evaluation_results)\n",
    "array = np.array(analysis_set['eval_set_score'])\n",
    "temp = array.argsort()[::-1]\n",
    "ranks = np.empty(len(array), int)\n",
    "ranks[temp] = np.arange(len(array))\n",
    "analysis_set['rank_test_score'] = ranks\n",
    "analysis_set.sort_values(by='rank_test_score', inplace=True)\n",
    "analysis_set.reset_index(drop=True, inplace=True)\n",
    "analysis_set.to_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run a grid search... auto_grid(X, y, labels, ks=range(10,100,10) opts=[1...12])\n",
      "-------------------------------------------------------------------------------\n",
      "\tRequired: X - matrix of descriptors\n",
      "\t\t  y - response values\n",
      "\t\t  labels - labels for structures\n",
      "\tOptional: ks - array of k-values (number of features to be selected\n",
      "\t\t  opts - array of option numbers where:\n",
      "\n",
      "            \t\t1: Random forest\n",
      "            \t\t2: Extra random trees\n",
      "            \t\t3: Simple OLS linear regression\n",
      "            \t\t4: Ridge regression\n",
      "            \t\t5: Ridge regression with cross validation (CV)\n",
      "            \t\t\t--** WARNING: Currently not working **--\n",
      "            \t\t6: Lasso (Least Absolute Shrinkage Selection Operator) regression\n",
      "            \t\t7: Lasso with CV\n",
      "            \t\t8: Lasso with least angle regression (lars) & CV\n",
      "            \t\t9: Lasso lars with information criterion (IC) - AIC/BIC\n",
      "             \t\t10: Elastic net regression\n",
      "            \t\t11: Elastic net with CV\n",
      "            \t\t12: Linear support vector regression\n"
     ]
    }
   ],
   "source": [
    "print rg.auto_grid.__doc__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "currind = 0\n",
    "to_drop = []\n",
    "for i in range(0, len(evaluation_results)-1):\n",
    "    if abs(evaluation_results.eval_set_score[currind] - evaluation_results.eval_set_score[i+1]) < 0.01 \\\n",
    "        and abs(evaluation_results.dev_set_score[i] - evaluation_results.dev_set_score[i+1]) < 0.01:\n",
    "        to_drop.append(i+1)\n",
    "    else:\n",
    "        currind = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in to_drop:\n",
    "    evaluation_results.drop(i, inplace=True)\n",
    "    \n",
    "evaluation_results.sort_values(by='rank_test_score', inplace=True)\n",
    "evaluation_results.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "to_drop = []\n",
    "for i in range(0, len(evaluation_results)-1):\n",
    "    if str(evaluation_results.method_ids[i])==str(evaluation_results.method_ids[i+1]):\n",
    "        to_drop.append(i+1)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "for i in to_drop:\n",
    "    evaluation_results.drop(i, inplace=True)\n",
    "\n",
    "evaluation_results.sort_values(by='rank_test_score', inplace=True)\n",
    "evaluation_results.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#array = np.array(evaluation_results['eval_set_score'])\n",
    "#temp = array.argsort()[::-1]\n",
    "#ranks = np.empty(len(array), int)\n",
    "#ranks[temp] = np.arange(len(array))\n",
    "#evaluation_results['rank_test_score'] = ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This file contains an evaluation and analysis set\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "Trying to write to wrong type of file, or analysis set already saved! Check the file...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-4f22333fe248>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./results.p'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-142-23a30a858144>\u001b[0m in \u001b[0;36msave_analysis\u001b[0;34m(analysis_results, filename)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Trying to write to wrong type of file, or analysis set already saved! Check the file...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mfile_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: Trying to write to wrong type of file, or analysis set already saved! Check the file..."
     ]
    }
   ],
   "source": [
    "save_analysis(evaluation_results, './results.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stuff = proj.file_loader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This file contains only an evaluation set\n",
      "This file contains an evaluation and analysis set\n",
      "5\n",
      "hi\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "stuff.load_file('./results.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dev_evs</th>\n",
       "      <th>dev_mae</th>\n",
       "      <th>dev_median_ae</th>\n",
       "      <th>dev_mse</th>\n",
       "      <th>dev_set_score</th>\n",
       "      <th>eval_evs</th>\n",
       "      <th>eval_mae</th>\n",
       "      <th>eval_median_ae</th>\n",
       "      <th>eval_mse</th>\n",
       "      <th>eval_set_score</th>\n",
       "      <th>method_ids</th>\n",
       "      <th>parameters</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.739102</td>\n",
       "      <td>0.623838</td>\n",
       "      <td>0.501034</td>\n",
       "      <td>0.639926</td>\n",
       "      <td>0.819417</td>\n",
       "      <td>0.694692</td>\n",
       "      <td>0.616625</td>\n",
       "      <td>0.441952</td>\n",
       "      <td>0.720915</td>\n",
       "      <td>0.787241</td>\n",
       "      <td>[7, 0, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.744669</td>\n",
       "      <td>0.617112</td>\n",
       "      <td>0.483138</td>\n",
       "      <td>0.626944</td>\n",
       "      <td>0.823081</td>\n",
       "      <td>0.699515</td>\n",
       "      <td>0.612576</td>\n",
       "      <td>0.466975</td>\n",
       "      <td>0.721839</td>\n",
       "      <td>0.786968</td>\n",
       "      <td>[8, 0, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.733978</td>\n",
       "      <td>0.636807</td>\n",
       "      <td>0.511334</td>\n",
       "      <td>0.669066</td>\n",
       "      <td>0.811194</td>\n",
       "      <td>0.710737</td>\n",
       "      <td>0.615025</td>\n",
       "      <td>0.434259</td>\n",
       "      <td>0.721846</td>\n",
       "      <td>0.786966</td>\n",
       "      <td>[5, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.745762</td>\n",
       "      <td>0.616421</td>\n",
       "      <td>0.480062</td>\n",
       "      <td>0.625489</td>\n",
       "      <td>0.823491</td>\n",
       "      <td>0.700215</td>\n",
       "      <td>0.612471</td>\n",
       "      <td>0.465889</td>\n",
       "      <td>0.721890</td>\n",
       "      <td>0.786953</td>\n",
       "      <td>[8, 0, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.733186</td>\n",
       "      <td>0.637282</td>\n",
       "      <td>0.511426</td>\n",
       "      <td>0.669930</td>\n",
       "      <td>0.810950</td>\n",
       "      <td>0.710194</td>\n",
       "      <td>0.615207</td>\n",
       "      <td>0.435337</td>\n",
       "      <td>0.721912</td>\n",
       "      <td>0.786947</td>\n",
       "      <td>[5, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.748417</td>\n",
       "      <td>0.614667</td>\n",
       "      <td>0.475049</td>\n",
       "      <td>0.621882</td>\n",
       "      <td>0.824509</td>\n",
       "      <td>0.701933</td>\n",
       "      <td>0.612238</td>\n",
       "      <td>0.459401</td>\n",
       "      <td>0.721978</td>\n",
       "      <td>0.786927</td>\n",
       "      <td>[8, 0, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.732047</td>\n",
       "      <td>0.637962</td>\n",
       "      <td>0.511549</td>\n",
       "      <td>0.671181</td>\n",
       "      <td>0.810597</td>\n",
       "      <td>0.709410</td>\n",
       "      <td>0.615465</td>\n",
       "      <td>0.436924</td>\n",
       "      <td>0.722020</td>\n",
       "      <td>0.786915</td>\n",
       "      <td>[5, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.694322</td>\n",
       "      <td>0.657794</td>\n",
       "      <td>0.518539</td>\n",
       "      <td>0.714293</td>\n",
       "      <td>0.798431</td>\n",
       "      <td>0.684489</td>\n",
       "      <td>0.627613</td>\n",
       "      <td>0.460684</td>\n",
       "      <td>0.736574</td>\n",
       "      <td>0.782620</td>\n",
       "      <td>[3, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.752357</td>\n",
       "      <td>0.632101</td>\n",
       "      <td>0.494662</td>\n",
       "      <td>0.648956</td>\n",
       "      <td>0.816869</td>\n",
       "      <td>0.711772</td>\n",
       "      <td>0.618592</td>\n",
       "      <td>0.453992</td>\n",
       "      <td>0.738298</td>\n",
       "      <td>0.782111</td>\n",
       "      <td>[5, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.4, u'n_alp...</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.732740</td>\n",
       "      <td>0.638443</td>\n",
       "      <td>0.486457</td>\n",
       "      <td>0.673809</td>\n",
       "      <td>0.809855</td>\n",
       "      <td>0.706970</td>\n",
       "      <td>0.624094</td>\n",
       "      <td>0.438201</td>\n",
       "      <td>0.738805</td>\n",
       "      <td>0.781961</td>\n",
       "      <td>[4, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.712333</td>\n",
       "      <td>0.643176</td>\n",
       "      <td>0.498564</td>\n",
       "      <td>0.684339</td>\n",
       "      <td>0.806884</td>\n",
       "      <td>0.673801</td>\n",
       "      <td>0.628156</td>\n",
       "      <td>0.458054</td>\n",
       "      <td>0.741350</td>\n",
       "      <td>0.781210</td>\n",
       "      <td>[6, 0, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.760021</td>\n",
       "      <td>0.618858</td>\n",
       "      <td>0.497022</td>\n",
       "      <td>0.623746</td>\n",
       "      <td>0.823983</td>\n",
       "      <td>0.708178</td>\n",
       "      <td>0.621593</td>\n",
       "      <td>0.435541</td>\n",
       "      <td>0.746938</td>\n",
       "      <td>0.779561</td>\n",
       "      <td>[6, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.715423</td>\n",
       "      <td>0.645702</td>\n",
       "      <td>0.518645</td>\n",
       "      <td>0.667201</td>\n",
       "      <td>0.811720</td>\n",
       "      <td>0.668582</td>\n",
       "      <td>0.625715</td>\n",
       "      <td>0.495734</td>\n",
       "      <td>0.747283</td>\n",
       "      <td>0.779459</td>\n",
       "      <td>[8, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.761455</td>\n",
       "      <td>0.617882</td>\n",
       "      <td>0.493286</td>\n",
       "      <td>0.622160</td>\n",
       "      <td>0.824431</td>\n",
       "      <td>0.709157</td>\n",
       "      <td>0.621469</td>\n",
       "      <td>0.437635</td>\n",
       "      <td>0.747285</td>\n",
       "      <td>0.779459</td>\n",
       "      <td>[6, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.715333</td>\n",
       "      <td>0.645763</td>\n",
       "      <td>0.518736</td>\n",
       "      <td>0.667319</td>\n",
       "      <td>0.811687</td>\n",
       "      <td>0.668516</td>\n",
       "      <td>0.625743</td>\n",
       "      <td>0.495719</td>\n",
       "      <td>0.747314</td>\n",
       "      <td>0.779450</td>\n",
       "      <td>[8, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.761590</td>\n",
       "      <td>0.617789</td>\n",
       "      <td>0.492898</td>\n",
       "      <td>0.622011</td>\n",
       "      <td>0.824473</td>\n",
       "      <td>0.709249</td>\n",
       "      <td>0.621457</td>\n",
       "      <td>0.437951</td>\n",
       "      <td>0.747320</td>\n",
       "      <td>0.779448</td>\n",
       "      <td>[6, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.753805</td>\n",
       "      <td>0.612044</td>\n",
       "      <td>0.464145</td>\n",
       "      <td>0.613458</td>\n",
       "      <td>0.826886</td>\n",
       "      <td>0.688871</td>\n",
       "      <td>0.623567</td>\n",
       "      <td>0.465434</td>\n",
       "      <td>0.748569</td>\n",
       "      <td>0.779080</td>\n",
       "      <td>[8, 0, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.727966</td>\n",
       "      <td>0.635300</td>\n",
       "      <td>0.502775</td>\n",
       "      <td>0.655139</td>\n",
       "      <td>0.815124</td>\n",
       "      <td>0.670222</td>\n",
       "      <td>0.630329</td>\n",
       "      <td>0.460665</td>\n",
       "      <td>0.748615</td>\n",
       "      <td>0.779066</td>\n",
       "      <td>[7, 0, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.753141</td>\n",
       "      <td>0.612524</td>\n",
       "      <td>0.463647</td>\n",
       "      <td>0.614427</td>\n",
       "      <td>0.826613</td>\n",
       "      <td>0.688424</td>\n",
       "      <td>0.623663</td>\n",
       "      <td>0.467851</td>\n",
       "      <td>0.748642</td>\n",
       "      <td>0.779058</td>\n",
       "      <td>[8, 0, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.727571</td>\n",
       "      <td>0.635538</td>\n",
       "      <td>0.502972</td>\n",
       "      <td>0.655631</td>\n",
       "      <td>0.814985</td>\n",
       "      <td>0.669901</td>\n",
       "      <td>0.630404</td>\n",
       "      <td>0.461174</td>\n",
       "      <td>0.748741</td>\n",
       "      <td>0.779029</td>\n",
       "      <td>[7, 0, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.748437</td>\n",
       "      <td>0.615994</td>\n",
       "      <td>0.466295</td>\n",
       "      <td>0.621203</td>\n",
       "      <td>0.824700</td>\n",
       "      <td>0.685186</td>\n",
       "      <td>0.624397</td>\n",
       "      <td>0.481655</td>\n",
       "      <td>0.749268</td>\n",
       "      <td>0.778873</td>\n",
       "      <td>[8, 0, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.709217</td>\n",
       "      <td>0.648809</td>\n",
       "      <td>0.456101</td>\n",
       "      <td>0.717894</td>\n",
       "      <td>0.797415</td>\n",
       "      <td>0.706953</td>\n",
       "      <td>0.641784</td>\n",
       "      <td>0.466925</td>\n",
       "      <td>0.760394</td>\n",
       "      <td>0.775590</td>\n",
       "      <td>[3, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 1.0, u'n_alp...</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.749687</td>\n",
       "      <td>0.621763</td>\n",
       "      <td>0.505157</td>\n",
       "      <td>0.636988</td>\n",
       "      <td>0.820246</td>\n",
       "      <td>0.685149</td>\n",
       "      <td>0.634194</td>\n",
       "      <td>0.470239</td>\n",
       "      <td>0.760898</td>\n",
       "      <td>0.775441</td>\n",
       "      <td>[6, 0, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.714051</td>\n",
       "      <td>0.645477</td>\n",
       "      <td>0.454366</td>\n",
       "      <td>0.711626</td>\n",
       "      <td>0.799184</td>\n",
       "      <td>0.707913</td>\n",
       "      <td>0.640131</td>\n",
       "      <td>0.460990</td>\n",
       "      <td>0.760953</td>\n",
       "      <td>0.775425</td>\n",
       "      <td>[4, 2, 9]</td>\n",
       "      <td>{u'normalize': True, u'positive': False, u'cri...</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.707464</td>\n",
       "      <td>0.653229</td>\n",
       "      <td>0.528076</td>\n",
       "      <td>0.680128</td>\n",
       "      <td>0.808072</td>\n",
       "      <td>0.663530</td>\n",
       "      <td>0.635869</td>\n",
       "      <td>0.458075</td>\n",
       "      <td>0.761125</td>\n",
       "      <td>0.775374</td>\n",
       "      <td>[7, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.707902</td>\n",
       "      <td>0.649701</td>\n",
       "      <td>0.456368</td>\n",
       "      <td>0.719311</td>\n",
       "      <td>0.797015</td>\n",
       "      <td>0.706007</td>\n",
       "      <td>0.642356</td>\n",
       "      <td>0.468621</td>\n",
       "      <td>0.761136</td>\n",
       "      <td>0.775371</td>\n",
       "      <td>[3, 2, 7]</td>\n",
       "      <td>{u'normalize': True, u'n_alphas': 260, u'fit_i...</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.707269</td>\n",
       "      <td>0.653343</td>\n",
       "      <td>0.528153</td>\n",
       "      <td>0.680364</td>\n",
       "      <td>0.808006</td>\n",
       "      <td>0.663397</td>\n",
       "      <td>0.635913</td>\n",
       "      <td>0.457949</td>\n",
       "      <td>0.761176</td>\n",
       "      <td>0.775359</td>\n",
       "      <td>[7, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.707560</td>\n",
       "      <td>0.649931</td>\n",
       "      <td>0.456474</td>\n",
       "      <td>0.719676</td>\n",
       "      <td>0.796912</td>\n",
       "      <td>0.705765</td>\n",
       "      <td>0.642497</td>\n",
       "      <td>0.468358</td>\n",
       "      <td>0.761319</td>\n",
       "      <td>0.775317</td>\n",
       "      <td>[3, 2, 7]</td>\n",
       "      <td>{u'normalize': True, u'n_alphas': 310, u'fit_i...</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.706498</td>\n",
       "      <td>0.653795</td>\n",
       "      <td>0.528483</td>\n",
       "      <td>0.681305</td>\n",
       "      <td>0.807740</td>\n",
       "      <td>0.662874</td>\n",
       "      <td>0.636078</td>\n",
       "      <td>0.458020</td>\n",
       "      <td>0.761378</td>\n",
       "      <td>0.775300</td>\n",
       "      <td>[7, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.707318</td>\n",
       "      <td>0.650090</td>\n",
       "      <td>0.456602</td>\n",
       "      <td>0.719927</td>\n",
       "      <td>0.796841</td>\n",
       "      <td>0.705601</td>\n",
       "      <td>0.642587</td>\n",
       "      <td>0.468873</td>\n",
       "      <td>0.761425</td>\n",
       "      <td>0.775285</td>\n",
       "      <td>[3, 2, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 1.0, u'n_alp...</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.550590</td>\n",
       "      <td>0.712954</td>\n",
       "      <td>0.562368</td>\n",
       "      <td>0.912872</td>\n",
       "      <td>0.742393</td>\n",
       "      <td>0.580783</td>\n",
       "      <td>0.675239</td>\n",
       "      <td>0.505763</td>\n",
       "      <td>0.837002</td>\n",
       "      <td>0.752981</td>\n",
       "      <td>[5, 1, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>1247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.603733</td>\n",
       "      <td>0.720595</td>\n",
       "      <td>0.565269</td>\n",
       "      <td>0.848397</td>\n",
       "      <td>0.760588</td>\n",
       "      <td>0.622767</td>\n",
       "      <td>0.708632</td>\n",
       "      <td>0.570301</td>\n",
       "      <td>0.841065</td>\n",
       "      <td>0.751782</td>\n",
       "      <td>[2, 2, 9]</td>\n",
       "      <td>{u'normalize': True, u'positive': False, u'cri...</td>\n",
       "      <td>1262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.806119</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.492557</td>\n",
       "      <td>0.564538</td>\n",
       "      <td>0.840691</td>\n",
       "      <td>0.726606</td>\n",
       "      <td>0.658499</td>\n",
       "      <td>0.512103</td>\n",
       "      <td>0.843655</td>\n",
       "      <td>0.751017</td>\n",
       "      <td>[6, 2, 9]</td>\n",
       "      <td>{u'normalize': False, u'positive': False, u'cr...</td>\n",
       "      <td>1263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.770162</td>\n",
       "      <td>0.626217</td>\n",
       "      <td>0.535170</td>\n",
       "      <td>0.645725</td>\n",
       "      <td>0.817781</td>\n",
       "      <td>0.716766</td>\n",
       "      <td>0.666046</td>\n",
       "      <td>0.481189</td>\n",
       "      <td>0.845424</td>\n",
       "      <td>0.750495</td>\n",
       "      <td>[3, 2, 10]</td>\n",
       "      <td>{u'normalize': True, u'alpha': 0, u'l1_ratio':...</td>\n",
       "      <td>1264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.533353</td>\n",
       "      <td>0.731591</td>\n",
       "      <td>0.612059</td>\n",
       "      <td>0.921334</td>\n",
       "      <td>0.740005</td>\n",
       "      <td>0.546803</td>\n",
       "      <td>0.675835</td>\n",
       "      <td>0.501723</td>\n",
       "      <td>0.849062</td>\n",
       "      <td>0.749422</td>\n",
       "      <td>[8, 1, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>1276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.504935</td>\n",
       "      <td>0.731396</td>\n",
       "      <td>0.610117</td>\n",
       "      <td>0.967370</td>\n",
       "      <td>0.727014</td>\n",
       "      <td>0.594080</td>\n",
       "      <td>0.700044</td>\n",
       "      <td>0.541446</td>\n",
       "      <td>0.850542</td>\n",
       "      <td>0.748985</td>\n",
       "      <td>[8, 1, 7]</td>\n",
       "      <td>{u'normalize': True, u'n_alphas': 160, u'fit_i...</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.530106</td>\n",
       "      <td>0.732692</td>\n",
       "      <td>0.611526</td>\n",
       "      <td>0.924453</td>\n",
       "      <td>0.739125</td>\n",
       "      <td>0.544051</td>\n",
       "      <td>0.676669</td>\n",
       "      <td>0.500438</td>\n",
       "      <td>0.850770</td>\n",
       "      <td>0.748918</td>\n",
       "      <td>[8, 1, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>1284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.497141</td>\n",
       "      <td>0.734525</td>\n",
       "      <td>0.602428</td>\n",
       "      <td>0.975076</td>\n",
       "      <td>0.724840</td>\n",
       "      <td>0.588283</td>\n",
       "      <td>0.702526</td>\n",
       "      <td>0.544397</td>\n",
       "      <td>0.855595</td>\n",
       "      <td>0.747494</td>\n",
       "      <td>[8, 1, 7]</td>\n",
       "      <td>{u'normalize': True, u'n_alphas': 210, u'fit_i...</td>\n",
       "      <td>1306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.569702</td>\n",
       "      <td>0.722565</td>\n",
       "      <td>0.631466</td>\n",
       "      <td>0.841763</td>\n",
       "      <td>0.762460</td>\n",
       "      <td>0.540087</td>\n",
       "      <td>0.682678</td>\n",
       "      <td>0.485593</td>\n",
       "      <td>0.859571</td>\n",
       "      <td>0.746320</td>\n",
       "      <td>[8, 2, 4]</td>\n",
       "      <td>{u'normalize': True, u'fit_intercept': True}</td>\n",
       "      <td>1339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.451734</td>\n",
       "      <td>0.749088</td>\n",
       "      <td>0.608370</td>\n",
       "      <td>0.987187</td>\n",
       "      <td>0.721422</td>\n",
       "      <td>0.501453</td>\n",
       "      <td>0.684844</td>\n",
       "      <td>0.497613</td>\n",
       "      <td>0.863123</td>\n",
       "      <td>0.745272</td>\n",
       "      <td>[8, 1, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>1340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.776571</td>\n",
       "      <td>0.619039</td>\n",
       "      <td>0.513424</td>\n",
       "      <td>0.630290</td>\n",
       "      <td>0.822136</td>\n",
       "      <td>0.707807</td>\n",
       "      <td>0.669490</td>\n",
       "      <td>0.470071</td>\n",
       "      <td>0.864982</td>\n",
       "      <td>0.744724</td>\n",
       "      <td>[4, 2, 10]</td>\n",
       "      <td>{u'normalize': False, u'alpha': 0, u'l1_ratio'...</td>\n",
       "      <td>1345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.447570</td>\n",
       "      <td>0.750434</td>\n",
       "      <td>0.611115</td>\n",
       "      <td>0.990570</td>\n",
       "      <td>0.720467</td>\n",
       "      <td>0.497802</td>\n",
       "      <td>0.686017</td>\n",
       "      <td>0.499541</td>\n",
       "      <td>0.865731</td>\n",
       "      <td>0.744503</td>\n",
       "      <td>[8, 1, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.534083</td>\n",
       "      <td>0.734079</td>\n",
       "      <td>0.596311</td>\n",
       "      <td>0.925011</td>\n",
       "      <td>0.738968</td>\n",
       "      <td>0.532096</td>\n",
       "      <td>0.685192</td>\n",
       "      <td>0.506913</td>\n",
       "      <td>0.868250</td>\n",
       "      <td>0.743759</td>\n",
       "      <td>[6, 1, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.4, u'n_alp...</td>\n",
       "      <td>1362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.729616</td>\n",
       "      <td>0.665953</td>\n",
       "      <td>0.524935</td>\n",
       "      <td>0.709743</td>\n",
       "      <td>0.799715</td>\n",
       "      <td>0.668276</td>\n",
       "      <td>0.697973</td>\n",
       "      <td>0.546733</td>\n",
       "      <td>0.878031</td>\n",
       "      <td>0.740872</td>\n",
       "      <td>[2, 2, 10]</td>\n",
       "      <td>{u'normalize': False, u'alpha': 0, u'l1_ratio'...</td>\n",
       "      <td>1372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.541978</td>\n",
       "      <td>0.737704</td>\n",
       "      <td>0.652997</td>\n",
       "      <td>0.874577</td>\n",
       "      <td>0.753200</td>\n",
       "      <td>0.520419</td>\n",
       "      <td>0.692700</td>\n",
       "      <td>0.512165</td>\n",
       "      <td>0.879264</td>\n",
       "      <td>0.740509</td>\n",
       "      <td>[7, 2, 4]</td>\n",
       "      <td>{u'normalize': True, u'fit_intercept': True}</td>\n",
       "      <td>1384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.422882</td>\n",
       "      <td>0.757920</td>\n",
       "      <td>0.615778</td>\n",
       "      <td>1.009943</td>\n",
       "      <td>0.715001</td>\n",
       "      <td>0.477688</td>\n",
       "      <td>0.693306</td>\n",
       "      <td>0.509715</td>\n",
       "      <td>0.879486</td>\n",
       "      <td>0.740443</td>\n",
       "      <td>[7, 1, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>1385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.735618</td>\n",
       "      <td>0.665637</td>\n",
       "      <td>0.522273</td>\n",
       "      <td>0.701986</td>\n",
       "      <td>0.801904</td>\n",
       "      <td>0.674743</td>\n",
       "      <td>0.698704</td>\n",
       "      <td>0.555863</td>\n",
       "      <td>0.880352</td>\n",
       "      <td>0.740187</td>\n",
       "      <td>[2, 2, 3]</td>\n",
       "      <td>{u'normalize': True, u'fit_intercept': False}</td>\n",
       "      <td>1387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.421128</td>\n",
       "      <td>0.758463</td>\n",
       "      <td>0.614793</td>\n",
       "      <td>1.011325</td>\n",
       "      <td>0.714611</td>\n",
       "      <td>0.476152</td>\n",
       "      <td>0.693819</td>\n",
       "      <td>0.510340</td>\n",
       "      <td>0.880572</td>\n",
       "      <td>0.740123</td>\n",
       "      <td>[7, 1, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.8, u'n_alp...</td>\n",
       "      <td>1389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.725819</td>\n",
       "      <td>0.671606</td>\n",
       "      <td>0.535260</td>\n",
       "      <td>0.709767</td>\n",
       "      <td>0.799708</td>\n",
       "      <td>0.667863</td>\n",
       "      <td>0.697610</td>\n",
       "      <td>0.525565</td>\n",
       "      <td>0.884596</td>\n",
       "      <td>0.738935</td>\n",
       "      <td>[2, 2, 4]</td>\n",
       "      <td>{u'normalize': False, u'fit_intercept': False}</td>\n",
       "      <td>1395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.506101</td>\n",
       "      <td>0.746404</td>\n",
       "      <td>0.645662</td>\n",
       "      <td>0.950568</td>\n",
       "      <td>0.731756</td>\n",
       "      <td>0.511875</td>\n",
       "      <td>0.692870</td>\n",
       "      <td>0.473515</td>\n",
       "      <td>0.885048</td>\n",
       "      <td>0.738801</td>\n",
       "      <td>[7, 1, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.4, u'n_alp...</td>\n",
       "      <td>1397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.525478</td>\n",
       "      <td>0.743138</td>\n",
       "      <td>0.650591</td>\n",
       "      <td>0.896135</td>\n",
       "      <td>0.747117</td>\n",
       "      <td>0.504712</td>\n",
       "      <td>0.700073</td>\n",
       "      <td>0.535032</td>\n",
       "      <td>0.895630</td>\n",
       "      <td>0.735679</td>\n",
       "      <td>[6, 2, 4]</td>\n",
       "      <td>{u'normalize': True, u'fit_intercept': True}</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.445400</td>\n",
       "      <td>0.759827</td>\n",
       "      <td>0.592218</td>\n",
       "      <td>0.998727</td>\n",
       "      <td>0.718166</td>\n",
       "      <td>0.470838</td>\n",
       "      <td>0.700127</td>\n",
       "      <td>0.486327</td>\n",
       "      <td>0.896699</td>\n",
       "      <td>0.735363</td>\n",
       "      <td>[7, 1, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.675823</td>\n",
       "      <td>0.663516</td>\n",
       "      <td>0.552594</td>\n",
       "      <td>0.787680</td>\n",
       "      <td>0.777722</td>\n",
       "      <td>0.653145</td>\n",
       "      <td>0.682258</td>\n",
       "      <td>0.539400</td>\n",
       "      <td>0.901762</td>\n",
       "      <td>0.733869</td>\n",
       "      <td>[5, 1, 9]</td>\n",
       "      <td>{u'normalize': True, u'positive': False, u'cri...</td>\n",
       "      <td>1419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.435712</td>\n",
       "      <td>0.762590</td>\n",
       "      <td>0.598814</td>\n",
       "      <td>1.006578</td>\n",
       "      <td>0.715950</td>\n",
       "      <td>0.462404</td>\n",
       "      <td>0.702793</td>\n",
       "      <td>0.488876</td>\n",
       "      <td>0.902035</td>\n",
       "      <td>0.733788</td>\n",
       "      <td>[7, 1, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>1421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.736167</td>\n",
       "      <td>0.637874</td>\n",
       "      <td>0.495982</td>\n",
       "      <td>0.724036</td>\n",
       "      <td>0.795682</td>\n",
       "      <td>0.695098</td>\n",
       "      <td>0.671311</td>\n",
       "      <td>0.486387</td>\n",
       "      <td>0.903170</td>\n",
       "      <td>0.733453</td>\n",
       "      <td>[5, 1, 9]</td>\n",
       "      <td>{u'normalize': False, u'positive': False, u'cr...</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.468627</td>\n",
       "      <td>0.758251</td>\n",
       "      <td>0.660417</td>\n",
       "      <td>0.982653</td>\n",
       "      <td>0.722702</td>\n",
       "      <td>0.478973</td>\n",
       "      <td>0.703630</td>\n",
       "      <td>0.489093</td>\n",
       "      <td>0.905926</td>\n",
       "      <td>0.732640</td>\n",
       "      <td>[7, 1, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.4, u'n_alp...</td>\n",
       "      <td>1423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.531155</td>\n",
       "      <td>0.737551</td>\n",
       "      <td>0.583274</td>\n",
       "      <td>0.892246</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.475383</td>\n",
       "      <td>0.707195</td>\n",
       "      <td>0.543245</td>\n",
       "      <td>0.908914</td>\n",
       "      <td>0.731758</td>\n",
       "      <td>[7, 0, 4]</td>\n",
       "      <td>{u'normalize': True, u'fit_intercept': True}</td>\n",
       "      <td>1424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.677915</td>\n",
       "      <td>0.677873</td>\n",
       "      <td>0.572106</td>\n",
       "      <td>0.774922</td>\n",
       "      <td>0.781322</td>\n",
       "      <td>0.623996</td>\n",
       "      <td>0.720576</td>\n",
       "      <td>0.548083</td>\n",
       "      <td>0.927032</td>\n",
       "      <td>0.726411</td>\n",
       "      <td>[6, 1, 9]</td>\n",
       "      <td>{u'normalize': True, u'positive': False, u'cri...</td>\n",
       "      <td>1426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.373999</td>\n",
       "      <td>0.779665</td>\n",
       "      <td>0.602904</td>\n",
       "      <td>1.054485</td>\n",
       "      <td>0.702431</td>\n",
       "      <td>0.407944</td>\n",
       "      <td>0.720262</td>\n",
       "      <td>0.516974</td>\n",
       "      <td>0.936280</td>\n",
       "      <td>0.723682</td>\n",
       "      <td>[7, 1, 11]</td>\n",
       "      <td>{u'normalize': True, u'l1_ratio': 0.6, u'n_alp...</td>\n",
       "      <td>1428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.552625</td>\n",
       "      <td>0.755980</td>\n",
       "      <td>0.606267</td>\n",
       "      <td>0.962445</td>\n",
       "      <td>0.728404</td>\n",
       "      <td>0.493804</td>\n",
       "      <td>0.761326</td>\n",
       "      <td>0.664197</td>\n",
       "      <td>1.000121</td>\n",
       "      <td>0.704841</td>\n",
       "      <td>[8, 2, 10]</td>\n",
       "      <td>{u'normalize': True, u'alpha': 10, u'l1_ratio'...</td>\n",
       "      <td>1430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dev_evs   dev_mae  dev_median_ae   dev_mse  dev_set_score  eval_evs  \\\n",
       "0    0.739102  0.623838       0.501034  0.639926       0.819417  0.694692   \n",
       "1    0.744669  0.617112       0.483138  0.626944       0.823081  0.699515   \n",
       "2    0.733978  0.636807       0.511334  0.669066       0.811194  0.710737   \n",
       "3    0.745762  0.616421       0.480062  0.625489       0.823491  0.700215   \n",
       "4    0.733186  0.637282       0.511426  0.669930       0.810950  0.710194   \n",
       "5    0.748417  0.614667       0.475049  0.621882       0.824509  0.701933   \n",
       "6    0.732047  0.637962       0.511549  0.671181       0.810597  0.709410   \n",
       "7    0.694322  0.657794       0.518539  0.714293       0.798431  0.684489   \n",
       "8    0.752357  0.632101       0.494662  0.648956       0.816869  0.711772   \n",
       "9    0.732740  0.638443       0.486457  0.673809       0.809855  0.706970   \n",
       "10   0.712333  0.643176       0.498564  0.684339       0.806884  0.673801   \n",
       "11   0.760021  0.618858       0.497022  0.623746       0.823983  0.708178   \n",
       "12   0.715423  0.645702       0.518645  0.667201       0.811720  0.668582   \n",
       "13   0.761455  0.617882       0.493286  0.622160       0.824431  0.709157   \n",
       "14   0.715333  0.645763       0.518736  0.667319       0.811687  0.668516   \n",
       "15   0.761590  0.617789       0.492898  0.622011       0.824473  0.709249   \n",
       "16   0.753805  0.612044       0.464145  0.613458       0.826886  0.688871   \n",
       "17   0.727966  0.635300       0.502775  0.655139       0.815124  0.670222   \n",
       "18   0.753141  0.612524       0.463647  0.614427       0.826613  0.688424   \n",
       "19   0.727571  0.635538       0.502972  0.655631       0.814985  0.669901   \n",
       "20   0.748437  0.615994       0.466295  0.621203       0.824700  0.685186   \n",
       "21   0.709217  0.648809       0.456101  0.717894       0.797415  0.706953   \n",
       "22   0.749687  0.621763       0.505157  0.636988       0.820246  0.685149   \n",
       "23   0.714051  0.645477       0.454366  0.711626       0.799184  0.707913   \n",
       "24   0.707464  0.653229       0.528076  0.680128       0.808072  0.663530   \n",
       "25   0.707902  0.649701       0.456368  0.719311       0.797015  0.706007   \n",
       "26   0.707269  0.653343       0.528153  0.680364       0.808006  0.663397   \n",
       "27   0.707560  0.649931       0.456474  0.719676       0.796912  0.705765   \n",
       "28   0.706498  0.653795       0.528483  0.681305       0.807740  0.662874   \n",
       "29   0.707318  0.650090       0.456602  0.719927       0.796841  0.705601   \n",
       "..        ...       ...            ...       ...            ...       ...   \n",
       "135  0.550590  0.712954       0.562368  0.912872       0.742393  0.580783   \n",
       "136  0.603733  0.720595       0.565269  0.848397       0.760588  0.622767   \n",
       "137  0.806119  0.583333       0.492557  0.564538       0.840691  0.726606   \n",
       "138  0.770162  0.626217       0.535170  0.645725       0.817781  0.716766   \n",
       "139  0.533353  0.731591       0.612059  0.921334       0.740005  0.546803   \n",
       "140  0.504935  0.731396       0.610117  0.967370       0.727014  0.594080   \n",
       "141  0.530106  0.732692       0.611526  0.924453       0.739125  0.544051   \n",
       "142  0.497141  0.734525       0.602428  0.975076       0.724840  0.588283   \n",
       "143  0.569702  0.722565       0.631466  0.841763       0.762460  0.540087   \n",
       "144  0.451734  0.749088       0.608370  0.987187       0.721422  0.501453   \n",
       "145  0.776571  0.619039       0.513424  0.630290       0.822136  0.707807   \n",
       "146  0.447570  0.750434       0.611115  0.990570       0.720467  0.497802   \n",
       "147  0.534083  0.734079       0.596311  0.925011       0.738968  0.532096   \n",
       "148  0.729616  0.665953       0.524935  0.709743       0.799715  0.668276   \n",
       "149  0.541978  0.737704       0.652997  0.874577       0.753200  0.520419   \n",
       "150  0.422882  0.757920       0.615778  1.009943       0.715001  0.477688   \n",
       "151  0.735618  0.665637       0.522273  0.701986       0.801904  0.674743   \n",
       "152  0.421128  0.758463       0.614793  1.011325       0.714611  0.476152   \n",
       "153  0.725819  0.671606       0.535260  0.709767       0.799708  0.667863   \n",
       "154  0.506101  0.746404       0.645662  0.950568       0.731756  0.511875   \n",
       "155  0.525478  0.743138       0.650591  0.896135       0.747117  0.504712   \n",
       "156  0.445400  0.759827       0.592218  0.998727       0.718166  0.470838   \n",
       "157  0.675823  0.663516       0.552594  0.787680       0.777722  0.653145   \n",
       "158  0.435712  0.762590       0.598814  1.006578       0.715950  0.462404   \n",
       "159  0.736167  0.637874       0.495982  0.724036       0.795682  0.695098   \n",
       "160  0.468627  0.758251       0.660417  0.982653       0.722702  0.478973   \n",
       "161  0.531155  0.737551       0.583274  0.892246       0.748214  0.475383   \n",
       "162  0.677915  0.677873       0.572106  0.774922       0.781322  0.623996   \n",
       "163  0.373999  0.779665       0.602904  1.054485       0.702431  0.407944   \n",
       "164  0.552625  0.755980       0.606267  0.962445       0.728404  0.493804   \n",
       "\n",
       "     eval_mae  eval_median_ae  eval_mse  eval_set_score  method_ids  \\\n",
       "0    0.616625        0.441952  0.720915        0.787241  [7, 0, 11]   \n",
       "1    0.612576        0.466975  0.721839        0.786968  [8, 0, 11]   \n",
       "2    0.615025        0.434259  0.721846        0.786966  [5, 2, 11]   \n",
       "3    0.612471        0.465889  0.721890        0.786953  [8, 0, 11]   \n",
       "4    0.615207        0.435337  0.721912        0.786947  [5, 2, 11]   \n",
       "5    0.612238        0.459401  0.721978        0.786927  [8, 0, 11]   \n",
       "6    0.615465        0.436924  0.722020        0.786915  [5, 2, 11]   \n",
       "7    0.627613        0.460684  0.736574        0.782620  [3, 2, 11]   \n",
       "8    0.618592        0.453992  0.738298        0.782111  [5, 2, 11]   \n",
       "9    0.624094        0.438201  0.738805        0.781961  [4, 2, 11]   \n",
       "10   0.628156        0.458054  0.741350        0.781210  [6, 0, 11]   \n",
       "11   0.621593        0.435541  0.746938        0.779561  [6, 2, 11]   \n",
       "12   0.625715        0.495734  0.747283        0.779459  [8, 2, 11]   \n",
       "13   0.621469        0.437635  0.747285        0.779459  [6, 2, 11]   \n",
       "14   0.625743        0.495719  0.747314        0.779450  [8, 2, 11]   \n",
       "15   0.621457        0.437951  0.747320        0.779448  [6, 2, 11]   \n",
       "16   0.623567        0.465434  0.748569        0.779080  [8, 0, 11]   \n",
       "17   0.630329        0.460665  0.748615        0.779066  [7, 0, 11]   \n",
       "18   0.623663        0.467851  0.748642        0.779058  [8, 0, 11]   \n",
       "19   0.630404        0.461174  0.748741        0.779029  [7, 0, 11]   \n",
       "20   0.624397        0.481655  0.749268        0.778873  [8, 0, 11]   \n",
       "21   0.641784        0.466925  0.760394        0.775590  [3, 2, 11]   \n",
       "22   0.634194        0.470239  0.760898        0.775441  [6, 0, 11]   \n",
       "23   0.640131        0.460990  0.760953        0.775425   [4, 2, 9]   \n",
       "24   0.635869        0.458075  0.761125        0.775374  [7, 2, 11]   \n",
       "25   0.642356        0.468621  0.761136        0.775371   [3, 2, 7]   \n",
       "26   0.635913        0.457949  0.761176        0.775359  [7, 2, 11]   \n",
       "27   0.642497        0.468358  0.761319        0.775317   [3, 2, 7]   \n",
       "28   0.636078        0.458020  0.761378        0.775300  [7, 2, 11]   \n",
       "29   0.642587        0.468873  0.761425        0.775285  [3, 2, 11]   \n",
       "..        ...             ...       ...             ...         ...   \n",
       "135  0.675239        0.505763  0.837002        0.752981  [5, 1, 11]   \n",
       "136  0.708632        0.570301  0.841065        0.751782   [2, 2, 9]   \n",
       "137  0.658499        0.512103  0.843655        0.751017   [6, 2, 9]   \n",
       "138  0.666046        0.481189  0.845424        0.750495  [3, 2, 10]   \n",
       "139  0.675835        0.501723  0.849062        0.749422  [8, 1, 11]   \n",
       "140  0.700044        0.541446  0.850542        0.748985   [8, 1, 7]   \n",
       "141  0.676669        0.500438  0.850770        0.748918  [8, 1, 11]   \n",
       "142  0.702526        0.544397  0.855595        0.747494   [8, 1, 7]   \n",
       "143  0.682678        0.485593  0.859571        0.746320   [8, 2, 4]   \n",
       "144  0.684844        0.497613  0.863123        0.745272  [8, 1, 11]   \n",
       "145  0.669490        0.470071  0.864982        0.744724  [4, 2, 10]   \n",
       "146  0.686017        0.499541  0.865731        0.744503  [8, 1, 11]   \n",
       "147  0.685192        0.506913  0.868250        0.743759  [6, 1, 11]   \n",
       "148  0.697973        0.546733  0.878031        0.740872  [2, 2, 10]   \n",
       "149  0.692700        0.512165  0.879264        0.740509   [7, 2, 4]   \n",
       "150  0.693306        0.509715  0.879486        0.740443  [7, 1, 11]   \n",
       "151  0.698704        0.555863  0.880352        0.740187   [2, 2, 3]   \n",
       "152  0.693819        0.510340  0.880572        0.740123  [7, 1, 11]   \n",
       "153  0.697610        0.525565  0.884596        0.738935   [2, 2, 4]   \n",
       "154  0.692870        0.473515  0.885048        0.738801  [7, 1, 11]   \n",
       "155  0.700073        0.535032  0.895630        0.735679   [6, 2, 4]   \n",
       "156  0.700127        0.486327  0.896699        0.735363  [7, 1, 11]   \n",
       "157  0.682258        0.539400  0.901762        0.733869   [5, 1, 9]   \n",
       "158  0.702793        0.488876  0.902035        0.733788  [7, 1, 11]   \n",
       "159  0.671311        0.486387  0.903170        0.733453   [5, 1, 9]   \n",
       "160  0.703630        0.489093  0.905926        0.732640  [7, 1, 11]   \n",
       "161  0.707195        0.543245  0.908914        0.731758   [7, 0, 4]   \n",
       "162  0.720576        0.548083  0.927032        0.726411   [6, 1, 9]   \n",
       "163  0.720262        0.516974  0.936280        0.723682  [7, 1, 11]   \n",
       "164  0.761326        0.664197  1.000121        0.704841  [8, 2, 10]   \n",
       "\n",
       "                                            parameters  rank_test_score  \n",
       "0    {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...                0  \n",
       "1    {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...               13  \n",
       "2    {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...               14  \n",
       "3    {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...               18  \n",
       "4    {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...               19  \n",
       "5    {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...               21  \n",
       "6    {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...               29  \n",
       "7    {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...               76  \n",
       "8    {u'normalize': True, u'l1_ratio': 0.4, u'n_alp...               77  \n",
       "9    {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...               96  \n",
       "10   {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...              136  \n",
       "11   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              155  \n",
       "12   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              158  \n",
       "13   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              159  \n",
       "14   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              161  \n",
       "15   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              162  \n",
       "16   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              172  \n",
       "17   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              177  \n",
       "18   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              179  \n",
       "19   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              184  \n",
       "20   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              187  \n",
       "21   {u'normalize': True, u'l1_ratio': 1.0, u'n_alp...              392  \n",
       "22   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              396  \n",
       "23   {u'normalize': True, u'positive': False, u'cri...              406  \n",
       "24   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              409  \n",
       "25   {u'normalize': True, u'n_alphas': 260, u'fit_i...              410  \n",
       "26   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              412  \n",
       "27   {u'normalize': True, u'n_alphas': 310, u'fit_i...              414  \n",
       "28   {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...              416  \n",
       "29   {u'normalize': True, u'l1_ratio': 1.0, u'n_alp...              417  \n",
       "..                                                 ...              ...  \n",
       "135  {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...             1247  \n",
       "136  {u'normalize': True, u'positive': False, u'cri...             1262  \n",
       "137  {u'normalize': False, u'positive': False, u'cr...             1263  \n",
       "138  {u'normalize': True, u'alpha': 0, u'l1_ratio':...             1264  \n",
       "139  {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...             1276  \n",
       "140  {u'normalize': True, u'n_alphas': 160, u'fit_i...             1280  \n",
       "141  {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...             1284  \n",
       "142  {u'normalize': True, u'n_alphas': 210, u'fit_i...             1306  \n",
       "143       {u'normalize': True, u'fit_intercept': True}             1339  \n",
       "144  {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...             1340  \n",
       "145  {u'normalize': False, u'alpha': 0, u'l1_ratio'...             1345  \n",
       "146  {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...             1357  \n",
       "147  {u'normalize': True, u'l1_ratio': 0.4, u'n_alp...             1362  \n",
       "148  {u'normalize': False, u'alpha': 0, u'l1_ratio'...             1372  \n",
       "149       {u'normalize': True, u'fit_intercept': True}             1384  \n",
       "150  {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...             1385  \n",
       "151      {u'normalize': True, u'fit_intercept': False}             1387  \n",
       "152  {u'normalize': True, u'l1_ratio': 0.8, u'n_alp...             1389  \n",
       "153     {u'normalize': False, u'fit_intercept': False}             1395  \n",
       "154  {u'normalize': True, u'l1_ratio': 0.4, u'n_alp...             1397  \n",
       "155       {u'normalize': True, u'fit_intercept': True}             1410  \n",
       "156  {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...             1411  \n",
       "157  {u'normalize': True, u'positive': False, u'cri...             1419  \n",
       "158  {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...             1421  \n",
       "159  {u'normalize': False, u'positive': False, u'cr...             1422  \n",
       "160  {u'normalize': True, u'l1_ratio': 0.4, u'n_alp...             1423  \n",
       "161       {u'normalize': True, u'fit_intercept': True}             1424  \n",
       "162  {u'normalize': True, u'positive': False, u'cri...             1426  \n",
       "163  {u'normalize': True, u'l1_ratio': 0.6, u'n_alp...             1428  \n",
       "164  {u'normalize': True, u'alpha': 10, u'l1_ratio'...             1430  \n",
       "\n",
       "[165 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuff.analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f8fe4d4d2f95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'all_data' is not defined"
     ]
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
